{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.src.utils import pad_sequences\n",
    "from pandas import get_dummies\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "outputs": [],
   "source": [
    "tokenizer = nltk.WordPunctTokenizer()\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "reviews_csv_name = 'reviews.csv'\n",
    "max_count_words = 150"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "outputs": [],
   "source": [
    "sizes_reviews = []\n",
    "mp = {}\n",
    "\n",
    "\n",
    "def normalize_review(review):\n",
    "    normalized_words = []\n",
    "\n",
    "    words = tokenizer.tokenize(review)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "\n",
    "        if re.search(\"^[a-z]+$\", word):\n",
    "            normalized_words.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "            if len(normalized_words) >= max_count_words:\n",
    "                break\n",
    "\n",
    "    sizes_reviews.append(len(normalized_words))\n",
    "    return normalized_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "outputs": [],
   "source": [
    "def map_word_to_num(matrix):\n",
    "    words = set()\n",
    "\n",
    "    for row in matrix:\n",
    "        words.update(row)\n",
    "\n",
    "    words = list(words)\n",
    "    return {words[i]: i for i in range(len(words))}\n",
    "\n",
    "\n",
    "def to_num_matrix(matrix):\n",
    "    global mp\n",
    "    mp = map_word_to_num(matrix)\n",
    "\n",
    "    num_matrix = []\n",
    "    for row in matrix:\n",
    "        num_row = []\n",
    "\n",
    "        for word in row:\n",
    "            num_row.append(mp[word])\n",
    "\n",
    "        num_matrix.append(num_row)\n",
    "\n",
    "    return num_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "outputs": [],
   "source": [
    "df = read_csv(reviews_csv_name)\n",
    "X = df['review'].map(lambda review: normalize_review(str(review)))\n",
    "X = pad_sequences(X, padding='post', value='#FILLER#', maxlen=max_count_words, dtype=object)\n",
    "X = to_num_matrix(X)\n",
    "Y = get_dummies(df['voted_up'].values).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=len(mp), output_dim=100, input_length=max_count_words))\n",
    "model.add(layers.Dropout(rate=0.1))\n",
    "model.add(layers.LSTM(units=100, dropout=0.1))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(units=2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "29/29 [==============================] - 9s 212ms/step - loss: 0.7038 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4900\n",
      "Epoch 2/16\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.6604 - accuracy: 0.5664 - val_loss: 0.6932 - val_accuracy: 0.4950\n",
      "Epoch 3/16\n",
      "29/29 [==============================] - 6s 195ms/step - loss: 0.6210 - accuracy: 0.5892 - val_loss: 0.6803 - val_accuracy: 0.5750\n",
      "Epoch 4/16\n",
      "29/29 [==============================] - 5s 182ms/step - loss: 0.4649 - accuracy: 0.7647 - val_loss: 0.5665 - val_accuracy: 0.7250\n",
      "Epoch 5/16\n",
      "29/29 [==============================] - 6s 193ms/step - loss: 0.3409 - accuracy: 0.8425 - val_loss: 0.5478 - val_accuracy: 0.6900\n",
      "Epoch 6/16\n",
      "29/29 [==============================] - 5s 184ms/step - loss: 0.2216 - accuracy: 0.9058 - val_loss: 0.5016 - val_accuracy: 0.8200\n",
      "Epoch 7/16\n",
      "29/29 [==============================] - 6s 192ms/step - loss: 0.1583 - accuracy: 0.9442 - val_loss: 0.4001 - val_accuracy: 0.8400\n",
      "Epoch 8/16\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 0.1228 - accuracy: 0.9536 - val_loss: 0.5069 - val_accuracy: 0.7550\n",
      "Epoch 9/16\n",
      "29/29 [==============================] - 6s 196ms/step - loss: 0.0933 - accuracy: 0.9658 - val_loss: 0.4311 - val_accuracy: 0.8125\n",
      "Epoch 10/16\n",
      "29/29 [==============================] - 5s 186ms/step - loss: 0.1140 - accuracy: 0.9592 - val_loss: 0.5353 - val_accuracy: 0.8175\n",
      "Epoch 11/16\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 0.1048 - accuracy: 0.9619 - val_loss: 0.5711 - val_accuracy: 0.7800\n",
      "Epoch 12/16\n",
      "29/29 [==============================] - 5s 177ms/step - loss: 0.1035 - accuracy: 0.9606 - val_loss: 0.5455 - val_accuracy: 0.7700\n",
      "Epoch 13/16\n",
      "29/29 [==============================] - 6s 194ms/step - loss: 0.0756 - accuracy: 0.9717 - val_loss: 0.4139 - val_accuracy: 0.8425\n",
      "Epoch 14/16\n",
      "29/29 [==============================] - 5s 187ms/step - loss: 0.0832 - accuracy: 0.9700 - val_loss: 0.5651 - val_accuracy: 0.8275\n",
      "Epoch 15/16\n",
      "29/29 [==============================] - 5s 181ms/step - loss: 0.0875 - accuracy: 0.9703 - val_loss: 2.0393 - val_accuracy: 0.6375\n",
      "Epoch 16/16\n",
      "29/29 [==============================] - 5s 184ms/step - loss: 0.1394 - accuracy: 0.9544 - val_loss: 0.4645 - val_accuracy: 0.7950\n",
      "32/32 [==============================] - 1s 25ms/step - loss: 0.4085 - accuracy: 0.8210\n",
      "\n",
      "loss: 0.40847718715667725\n",
      "accuracy: 0.8209999799728394\n"
     ]
    }
   ],
   "source": [
    "epochs = 16\n",
    "batch_size = 128\n",
    "\n",
    "model.fit(np.array(X_train), np.array(Y_train), epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
    "\n",
    "tests = model.evaluate(np.array(X_test), np.array(Y_test))\n",
    "print('\\n' + 'loss: ' + str(tests[0]) + '\\n' + 'accuracy: ' + str(tests[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "    normalized_review = normalize_review(review)\n",
    "    for _ in range(max_count_words - len(normalized_review)):\n",
    "        normalized_review.append('#FILLER#')\n",
    "    num_normalized_review = [mp[word] for word in normalized_review]\n",
    "    answer = model.predict(np.array(num_normalized_review).reshape(1, 150))\n",
    "    print(answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "[[0.08944421 0.9105558 ]]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "[[0.85134304 0.14865696]]\n"
     ]
    }
   ],
   "source": [
    "predict(\"Excellent\")\n",
    "predict(\"Terrible\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
